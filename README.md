# ğŸ“° E-Newspaper Automation

> Automated daily download of **The Hindu** and **The Indian Express** newspapers from IndiaGS, with Discord integration for students preparing for competitive exams.

[![GitHub Actions](https://img.shields.io/badge/GitHub%20Actions-Automated-blue)](https://github.com/features/actions)
[![Python 3.11](https://img.shields.io/badge/Python-3.11-blue)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“š Documentation

- ï¿½ **[Getting Started](GETTING_STARTED.md)** - Visual step-by-step guide
- ğŸ“– **[Quick Start](QUICKSTART.md)** - Get running in 5 minutes
- ğŸ“– **[Setup Guide](SETUP_GUIDE.md)** - Detailed setup instructions  
- ğŸ—ï¸ **[Architecture](ARCHITECTURE.md)** - System design & diagrams
- ğŸ“Š **[Project Summary](PROJECT_SUMMARY.md)** - Comprehensive overview
- âœ… **[Testing Checklist](TESTING_CHECKLIST.md)** - Verify your setup
- ğŸ”§ **[Troubleshooting](TROUBLESHOOTING.md)** - Fix common issues

## ğŸ¯ Features

- âœ… **Automated Daily Downloads**: Runs at 6:00 AM IST via GitHub Actions
- ğŸ“ **Organized Storage**: PDFs stored in `e-paper/MMMYY/` folders (e.g., `DEC25/`)
- ğŸ—œï¸ **PDF Compression**: Optional compression to save storage space
- ğŸ“Š **History Tracking**: JSON-based tracking to avoid duplicate downloads
- ğŸ§¹ **Auto Cleanup**: Deletes old month folders after 7 days into new month
- ğŸ’¬ **Discord Integration**: Posts download links to Discord via webhook
- ğŸ”„ **Fallback System**: Stores original links if download/compression fails

## ğŸš€ Setup

### 1. Fork/Clone Repository

```bash
git clone https://github.com/YOUR_USERNAME/epaper-automation.git
cd epaper-automation
```

### 2. Configure Discord Webhook

1. Go to your Discord server settings
2. Navigate to **Integrations** â†’ **Webhooks**
3. Create a new webhook for your newspaper channel
4. Copy the webhook URL

### 3. Set GitHub Secrets

1. Go to your repository on GitHub
2. Navigate to **Settings** â†’ **Secrets and variables** â†’ **Actions**
3. Add a new repository secret:
   - **Name**: `DISCORD_WEBHOOK_URL`
   - **Value**: Your Discord webhook URL

### 4. Enable GitHub Actions

1. Go to the **Actions** tab in your repository
2. Enable workflows if prompted
3. The workflow will run automatically daily at 6:00 AM IST

## ğŸ§ª Manual Testing

Install dependencies locally:

```bash
pip install -r requirements.txt
```

Set environment variable:

```bash
export DISCORD_WEBHOOK_URL="your_webhook_url_here"
```

Run the scraper:

```bash
python scraper.py
```

## ğŸ“‚ Folder Structure

```
epaper-automation/
â”œâ”€â”€ scraper.py                 # Main automation script
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ download_history.json      # Download history (auto-generated)
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ daily-newspaper.yml  # GitHub Actions workflow
â””â”€â”€ e-paper/                   # Downloaded newspapers (auto-generated)
    â”œâ”€â”€ DEC25/
    â”‚   â”œâ”€â”€ TH_2025-12-17.pdf
    â”‚   â””â”€â”€ IE_2025-12-17.pdf
    â””â”€â”€ JAN26/
        â””â”€â”€ ...
```

## ğŸ”§ Configuration

### Change Schedule

Edit [.github/workflows/daily-newspaper.yml](.github/workflows/daily-newspaper.yml):

```yaml
schedule:
  - cron: '30 0 * * *'  # 6:00 AM IST (00:30 UTC)
```

### Add More Newspapers

Edit `NEWSPAPERS` dict in [scraper.py](scraper.py):

```python
NEWSPAPERS = {
    "The Hindu": "TH",
    "Indian Express": "IE",
    "Times of India": "TOI"  # Add more
}
```

## ğŸ“Š How It Works

1. **Scrape Main Page**: Access IndiaGS homepage and locate target newspapers
2. **Navigate Pages**: Click through intermediate ad/promo pages
3. **Wait for Timer**: Handle 15-second countdown timer on download page
4. **Extract PDF URL**: Parse JavaScript to get actual PDF download link
5. **Download PDF**: Fetch PDF file via requests
6. **Compress (Optional)**: Use pypdf to compress if available
7. **Post to Discord**: Send embed with download info
8. **Update History**: Track processed newspapers in JSON
9. **Cleanup**: Delete old folders on 8th of each month

## ğŸ› ï¸ Technologies

- **Python 3.11**: Core automation
- **Selenium**: Web automation and scraping
- **Requests**: HTTP requests for downloads
- **pypdf**: PDF compression
- **GitHub Actions**: Scheduled execution
- **Discord Webhooks**: Notifications

## âš ï¸ Important Notes

- PDFs are stored in the repository (ensure you have enough storage)
- GitHub free tier has 500MB storage - consider using Git LFS for larger files
- The scraper respects the website's timer requirements
- Fallback links are stored if PDF download fails

## ğŸ› Troubleshooting

### No newspapers downloaded

- Check GitHub Actions logs
- Verify Discord webhook URL is correct
- Ensure the website structure hasn't changed

### Storage issues

- Enable Git LFS: `git lfs install && git lfs track "*.pdf"`
- Or modify script to only post links (not store PDFs)

### Chrome/ChromeDriver errors

- GitHub Actions handles this automatically
- For local testing, install Chrome and ChromeDriver manually

## ğŸ“œ License

See [LICENSE](LICENSE) file.

## ğŸ¤ Contributing

Feel free to open issues or submit PRs for improvements!

---

**Made for students preparing for competitive exams** ğŸ“š
